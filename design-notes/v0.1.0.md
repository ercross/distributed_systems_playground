# v0.1.0 — Naive Failure-First Baseline

## Status
**Intentionally fragile.**  
This version establishes the baseline behavior of the system **before** any reliability constraints are introduced.


## Context

The system consists of three independent services:

- **Order API** — accepts incoming HTTP requests
- **Order Processor** — consumes order events and performs work
- **Payment Service** — downstream dependency that exhibits random latency and failures

All services communicate over the network and fail independently.

This version represents the default shape of many early distributed systems:  
a working happy path with no explicit failure handling.


## Design Intent

The intent of `v0.1.0` is **not correctness or stability**.

It exists to answer one question:

> *How does the system behave when it is allowed to accept unlimited work under partial failure?*

To answer this honestly, the system intentionally violates common best practices.


## Deliberate Design Choices

This version includes **no defensive constraints**:

- No admission control
- No backpressure
- No bounded concurrency
- No timeouts
- No retry limits
- No idempotency
- Best-effort request handling only

These omissions are intentional and required for the experiment.


## Expected Behavior Under Load

When subjected to sustained concurrency:

- Incoming requests are accepted indefinitely
- In-flight work accumulates
- Goroutines block waiting on downstream calls
- Queues grow silently
- Latency increases without bound
- Errors appear late and inconsistently
- CPU and memory remain deceptively normal

The system does not crash.
It drowns quietly.

This is a textbook example of **partial failure**.


## How to Reproduce


```bash
git checkout v0.1.0
make deploy

````

In another terminal, at project root:

```bash
vegeta attack -targets=vegeta/targets/dsp.txt -rate=50   -duration=20s > vegeta/results/50rps.bin
vegeta attack -targets=vegeta/targets/dsp.txt -rate=100  -duration=20s > vegeta/results/100rps.bin
vegeta attack -targets=vegeta/targets/dsp.txt -rate=200  -duration=20s > vegeta/results/200rps.bin
vegeta attack -targets=vegeta/targets/dsp.txt -rate=1000 -duration=20s > vegeta/results/1000rps.bin

vegeta report vegeta/results/Xrps.bin
```


### The Load Test Command


```bash
vegeta attack \
  -targets=vegeta/targets/dsp.txt \
  -rate=50 \
  -duration=20s \
  > vegeta/results/results-50rps.bin
```

Key flags:

* `-rate` → requests per second
* `-duration` → how long to apply load
* output redirected to a `.bin` file (important)


## Understanding the Rate

When you run:

```
-rate=100
```

You are not saying:

> “Handle 100 RPS”

You are saying:

> “I will send 100 requests per second, regardless of whether you can handle them.”

This distinction is crucial for this lesson.


### Viewing Results in the Terminal

#### Basic summary

```bash
vegeta report vegeta/results/50rps.bin
```

You’ll see:

* request rate vs throughput
* latency percentiles
* success ratio
* error types

Focus on:

* **throughput**
* **latency distribution**
* **error patterns**

Not CPU. Not memory. Yet.


#### Viewing Results in the Browser

Vegeta can generate an interactive latency plot.

```bash
vegeta plot vegeta/results/50rps.bin > plot.html
open plot.html
```

What to look for:

* long flat tails
* sudden latency cliffs
* widening spread under load

These are **queueing symptoms**, not slow code.


## Observed Failure Modes

Under load, the system exhibits:

* Throughput collapse well below request rate
* Latency cliffs and long tails
* Connection exhaustion
* Timeout-driven failures
* Inconsistent success ratios

These failures emerge from **coordination pressure**, not resource exhaustion.


## Why This Matters

This version demonstrates a critical distributed systems truth:

> **Most systems fail due to unbounded concurrency, not lack of compute.**

The absence of constraints allows the system to accept work it cannot complete, leading to cascading degradation that is difficult to diagnose after the fact.


## Lessons Learned

* Partial failure is the default, not the exception
* Accepting unlimited work is a correctness bug
* Latency growth is often a symptom of queueing, not slow execution
* Systems must learn how to say “no” before they can scale


## Next Step

The next version introduces the **first constraint**:

> Explicitly limiting how much work the system is allowed to accept.

Reliability will be earned incrementally, one rule at a time.

```
